{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import layers\n",
    "import datetime\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializer for the layers.\n",
    "kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "# Gamma initializer for instance normalization.\n",
    "gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the file names from the Tfrec files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONET_FILENAMES = tf.io.gfile.glob('gan-getting-started/monet_tfrec/*.tfrec')\n",
    "print('Monet TFRecord Files:', len(MONET_FILENAMES))\n",
    "\n",
    "PHOTO_FILENAMES = tf.io.gfile.glob('gan-getting-started/photo_tfrec/*.tfrec')\n",
    "print('Photo TFRecord Files:', len(PHOTO_FILENAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions to decode the tfrecords into datasets usable by our model. channels=3 because the images are RGB. We don't need the labels so we just return the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [256, 256]\n",
    "\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    tfrecord = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord)\n",
    "    image = decode_image(example['image'])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using the above file names and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet_ds = load_dataset(MONET_FILENAMES, labeled=True).batch(1)\n",
    "photo_ds = load_dataset(PHOTO_FILENAMES, labeled=True).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying an example photo from each of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_monet = next(iter(monet_ds))\n",
    "example_photo = next(iter(photo_ds))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Photo')\n",
    "plt.imshow(example_photo[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Monet')\n",
    "plt.imshow(example_monet[0] * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset has been created we can start defining the models\n",
    "\n",
    "<h1>Defining the models</h1>\n",
    "\n",
    "before we define the models themselves, we will define some custom layer blocks which will be used by the generators and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding(layers.Layer):\n",
    "    def __init__(self, padding=(1,1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        padding_width, padding_height = self.padding\n",
    "        padding_tensor = [\n",
    "            [0,0],\n",
    "            [padding_height, padding_height],\n",
    "            [padding_width, padding_width],\n",
    "            [0,0]\n",
    "        ]\n",
    "        return tf.pad(input_tensor, padding_tensor, mode='REFLECT')\n",
    "\n",
    "\n",
    "def residual_block(x, activation, kernel_initializer=kernel_init, gamma_initializer=gamma_init, kernel_size=(3,3), strides=(1,1), padding='valid', use_bias=False):\n",
    "    dim = x.shape[-1]\n",
    "    input_tensor = x\n",
    "\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = ReflectionPadding()(input_tensor)\n",
    "    x = layers.Conv2D(dim, kernel_size, strides=strides, padding=padding, use_bias=use_bias, kernel_initializer=kernel_initializer)(x)\n",
    "\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = ReflectionPadding()(x)\n",
    "    x = layers.Conv2D(dim, kernel_size, strides=strides, padding=padding, use_bias=use_bias, kernel_initializer=kernel_initializer)(x)\n",
    "\n",
    "    x = layers.add([input_tensor, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def downsample(x, filters, activation, kernel_initizalizer=kernel_init, kernel_size=(3,3), strides=(2,2), padding=\"same\", gamma_initializer=gamma_init, use_bias=False):\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias, kernel_initializer=kernel_initizalizer)(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "def upsample(x, filters, activation, kernel_initializer=kernel_init, kernel_size=(3,3), strides=(2,2), padding=\"same\", gamma_initializer=gamma_init, use_bias=False):\n",
    "    x = layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias, kernel_initializer=kernel_initializer)(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Actually building the Generator and Discriminator Models</h1>\n",
    "\n",
    "Because we defined the custom layers above, we can simplify the structure of the generator to use differing amount and ratios of these block layers, which simplfies the structure of the generator greatly. By default we will use two downsampling layers, followed by 9 residual layers, then two upsampling layer to restore the original size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(filters=64, num_downsampling_blocks=2, num_res_blocks=9, num_upsampling_blocks=2, gamma_initializer=gamma_init, name=None):\n",
    "    img_input = layers.Input(shape=(256,256,3), name=name+'_img_input')\n",
    "    x = ReflectionPadding(padding=(3,3))(img_input)\n",
    "    x = layers.Conv2D(filters, (7,7), padding='valid', kernel_initializer=kernel_init)(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    #processing downsampling blocks\n",
    "    for i in range(num_downsampling_blocks):\n",
    "        filters *= 2\n",
    "        x = downsample(x, filters=filters, activation=layers.Activation('relu'))\n",
    "\n",
    "    #processing residual blocks\n",
    "    for i in range(num_res_blocks):\n",
    "        x = residual_block(x, activation=layers.Activation('relu'))\n",
    "\n",
    "    #processing upsampling blocks\n",
    "    for i in range(num_upsampling_blocks):\n",
    "        filters //= 2\n",
    "        x = upsample(x, filters=filters, activation=layers.Activation('relu'))\n",
    "\n",
    "    x = ReflectionPadding(padding=(3,3))(x)\n",
    "    x = layers.Conv2D(3, (7,7), padding='valid')(x)\n",
    "    x = layers.Activation('tanh')(x)\n",
    "\n",
    "    model = keras.models.Model(img_input, x, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(filters=64, kernel_initializer=kernel_init, num_downsampling_layers=3, name=None):\n",
    "    img_input = layers.Input(shape=(256,256,3), name=name+'_img_input')\n",
    "    x = layers.Conv2D(filters, (7,7), strides=(2,2), padding='same', kernel_initializer=kernel_initializer)(img_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    num_filters = filters\n",
    "    for i in range(num_downsampling_layers):\n",
    "        num_filters *= 2\n",
    "        if (i < num_downsampling_layers -1):\n",
    "            x = downsample(x, filters=num_filters, activation=layers.LeakyReLU(0.2), kernel_size=(4,4), strides=(2,2))\n",
    "        else:\n",
    "            x = downsample(x, filters=num_filters, activation=layers.LeakyReLU(0.2), kernel_size=(4,4), strides=(1,1))\n",
    "\n",
    "    x = layers.Conv2D(1, (4,4), strides=(1,1), padding='same', kernel_initializer=kernel_initializer)(x)\n",
    "    model = keras.models.Model(inputs=img_input, outputs=x, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the models\n",
    "gen_Monet = build_generator(name='gen_Monet',num_res_blocks=7)\n",
    "gen_Photo = build_generator(name='gen_Photo', num_res_blocks=7)\n",
    "\n",
    "disc_Monet = build_discriminator(name='disc_Monet')\n",
    "disc_Photo = build_discriminator(name='disc_Photo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan(keras.Model):\n",
    "    def __init__(self, gen_Monet, gen_Photo, disc_Monet, disc_Photo, lambda_cycle=10.0, lambda_identity=0.5):\n",
    "        super().__init__()\n",
    "        self.gen_Monet = gen_Monet\n",
    "        self.gen_Photo = gen_Photo\n",
    "        self.disc_Monet = disc_Monet\n",
    "        self.disc_Photo = disc_Photo\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        self.lambda_identity = lambda_identity\n",
    "\n",
    "    def compile(self, gen_Monet_optimizer, gen_Photo_optimizer, disc_Monet_optimizer, disc_Photo_optimizer, gen_loss_fn, disc_loss_fn):\n",
    "        super().compile()\n",
    "        self.gen_Monet_optimizer = gen_Monet_optimizer\n",
    "        self.gen_Photo_optimizer = gen_Photo_optimizer\n",
    "        self.disc_Monet_optimizer = disc_Monet_optimizer\n",
    "        self.disc_Photo_optimizer = disc_Photo_optimizer\n",
    "        self.generator_loss_fn = gen_loss_fn\n",
    "        self.discriminator_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n",
    "        self.identity_loss_fn = keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        real_Photo, real_Monet = batch_data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            #generating the fake images\n",
    "            fake_Monet = self.gen_Monet(real_Photo, training=True)\n",
    "            cycled_Photo = self.gen_Photo(fake_Monet, training=True)\n",
    "\n",
    "            fake_Photo = self.gen_Photo(real_Monet, training=True)\n",
    "            cycled_Monet = self.gen_Monet(fake_Photo, training=True)\n",
    "\n",
    "            #identity loss\n",
    "            same_Photo = self.gen_Photo(real_Photo, training=True)\n",
    "            same_Monet = self.gen_Monet(real_Monet, training=True)\n",
    "\n",
    "            #discriminator loss\n",
    "            disc_real_Photo = self.disc_Photo(real_Photo, training=True)\n",
    "            disc_real_Monet = self.disc_Monet(real_Monet, training=True)\n",
    "\n",
    "            disc_fake_Photo = self.disc_Photo(fake_Photo, training=True)\n",
    "            disc_fake_Monet = self.disc_Monet(fake_Monet, training=True)\n",
    "\n",
    "            #generator adverserial loss\n",
    "            gen_Monet_loss = self.generator_loss_fn(disc_fake_Monet)\n",
    "            gen_Photo_loss = self.generator_loss_fn(disc_fake_Photo)\n",
    "\n",
    "            #generator cycle loss\n",
    "            cycle_Monet_loss = self.cycle_loss_fn(real_Monet, cycled_Monet) * self.lambda_cycle\n",
    "            cycle_Photo_loss = self.cycle_loss_fn(real_Photo, cycled_Photo) * self.lambda_cycle\n",
    "\n",
    "            #generator identity loss\n",
    "            id_Monet_loss = (self.identity_loss_fn(real_Monet, same_Monet) * self.lambda_cycle * self.lambda_identity)\n",
    "            id_Photo_loss = (self.identity_loss_fn(real_Photo, same_Photo) * self.lambda_cycle * self.lambda_identity)\n",
    "\n",
    "            #total generator loss\n",
    "            total_loss_Monet = gen_Monet_loss + cycle_Monet_loss + id_Monet_loss\n",
    "            total_loss_Photo = gen_Photo_loss + cycle_Photo_loss + id_Photo_loss\n",
    "\n",
    "            #discriminator loss\n",
    "            disc_Photo_loss = self.discriminator_loss_fn(disc_real_Photo, disc_fake_Photo)\n",
    "            disc_Monet_loss = self.discriminator_loss_fn(disc_real_Monet, disc_fake_Monet)\n",
    "\n",
    "        #get gradients for the generators\n",
    "        gen_Monet_gradients = tape.gradient(total_loss_Monet, self.gen_Monet.trainable_variables)\n",
    "        gen_Photo_gradients = tape.gradient(total_loss_Photo, self.gen_Photo.trainable_variables)\n",
    "\n",
    "        #get gradients for the discriminators\n",
    "        disc_Monet_gradients = tape.gradient(disc_Monet_loss, self.disc_Monet.trainable_variables)\n",
    "        disc_Photo_gradients = tape.gradient(disc_Photo_loss, self.disc_Photo.trainable_variables)\n",
    "\n",
    "        self.gen_Monet_optimizer.apply_gradients(zip(gen_Monet_gradients, self.gen_Monet.trainable_variables))\n",
    "        self.gen_Photo_optimizer.apply_gradients(zip(gen_Photo_gradients, self.gen_Photo.trainable_variables))\n",
    "\n",
    "        self.disc_Monet_optimizer.apply_gradients(zip(disc_Monet_gradients, self.disc_Monet.trainable_variables))\n",
    "        self.disc_Photo_optimizer.apply_gradients(zip(disc_Photo_gradients, self.disc_Photo.trainable_variables))   \n",
    "\n",
    "        return {\n",
    "            \"gen_Monet_loss\": total_loss_Monet,\n",
    "            \"gen_Photo_loss\": total_loss_Photo,\n",
    "            \"disc_Monet_loss\": disc_Monet_loss,\n",
    "            \"disc_Photo_loss\": disc_Photo_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a callback function to create images during the training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filepath = 'img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=4):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        _, ax = plt.subplots(4, 2, figsize=(12, 12))\n",
    "        for i, img in enumerate(photo_ds.take(self.num_img)):\n",
    "            prediction = self.model.gen_Monet(img)[0].numpy()\n",
    "            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "            img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "            ax[i, 0].imshow(img)\n",
    "            ax[i, 1].imshow(prediction)\n",
    "            ax[i, 0].set_title(\"Input image\")\n",
    "            ax[i, 1].set_title(\"Translated image\")\n",
    "            ax[i, 0].axis(\"off\")\n",
    "            ax[i, 1].axis(\"off\")\n",
    "\n",
    "            prediction = keras.preprocessing.image.array_to_img(prediction)\n",
    "            prediction.save(img_filepath + \"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch + 1))\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the loss functions for the gan\n",
    "adv_loss_fn = keras.losses.MeanSquaredError()\n",
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def generator_loss_fn(fake):\n",
    "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
    "    return fake_loss\n",
    "\n",
    "def discriminator_loss_fn(real, fake):\n",
    "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
    "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
    "    total_disc_loss = (real_loss + fake_loss) * 0.5\n",
    "    return total_disc_loss\n",
    "\n",
    "\n",
    "#creating the gan model\n",
    "cycle_gan_model = CycleGan(\n",
    "    gen_Monet, gen_Photo, disc_Monet, disc_Photo)\n",
    "\n",
    "\n",
    "cycle_gan_model.compile(\n",
    "    gen_Monet_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    gen_Photo_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    disc_Monet_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    disc_Photo_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    gen_loss_fn=generator_loss_fn,\n",
    "    disc_loss_fn=discriminator_loss_fn,\n",
    "    metrics=['accuracy','loss'])\n",
    "\n",
    "plotter = GANMonitor()\n",
    "checkpoint_filepath = \"./model_checkpoint/cyclegan_checkpoints_{epoch:03d}\"\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((photo_ds, monet_ds)),\n",
    "    epochs=100,\n",
    "    callbacks=[plotter, model_checkpoint_callback, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using tensorboard to visualize training metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Checkpoints to skip training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = \"./model_checkpoint/cyclegan_checkpoints_093.index\"\n",
    "cycle_gan_model.load_weights(weight_file).expect_partial()\n",
    "print(\"Weights loaded successfully\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create gif files for the training example images to show how the network learned over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    anim_file = 'generated_gif_{i}.gif'.format(i=i)\n",
    "\n",
    "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "        filenames = glob.glob(img_filepath + 'generated_img_{i}_*.png'.format(i=i))\n",
    "        filenames = sorted(filenames)\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Displaying Some Example Images</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_display_image(model, input_img):\n",
    "    prediction = model.gen_Monet(img)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "    plt.imgshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8689fac7afca8cfd8aa85671ea19899a8f2204abddab2f8fabdacf0ec105764e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
